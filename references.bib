@manual{adaptalint_conway_23,
  author = {Max Conway and Natasha Latysheva},
  note   = {R package version 0.2.4},
  title  = {adaptalint: Check Code Style Painlessly},
  url    = {https://CRAN.R-project.org/package=adaptalint},
  year   = {2019}
}

@book{alexander_telling_2023,
  abstract   = {The book equips students with the end-to-end skills needed to do data science. That means gathering, cleaning, preparing, and sharing data, then using statistical models to analyse data, writing about the results of those models, drawing conclusions from them, and finally, using the cloud to put a model into production, all done in a reproducible way. At the moment, there are a lot of books that teach data science, but most of them assume that you already have the data. This book fills that gap by detailing how to go about gathering datasets, cleaning and preparing them, before analysing them. There are also a lot of books that teach statistical modelling, but few of them teach how to communicate the results of the models and how they help us learn about the world. Very few data science textbooks cover ethics, and most of those that do, have a token ethics chapter. Finally, reproducibility is not often emphasised in data science books. This book is based around a straight-forward workflow conducted in an ethical and reproducible way: gather data, prepare data, analyse data, and communicate those findings. This book will achieve the goals by working through extensive case studies in terms of gathering and preparing data, and integrating ethics throughout. It is specifically designed around teaching how to write about the data and models, so aspects such as writing are explicitly covered. And finally, the use of GitHub and the open-source statistical language R are built in throughout the book. Key Features:   Extensive code examples.   Ethics integrated throughout.   Reproducibility integrated throughout.   Focus on data gathering, messy data, and cleaning data.  Extensive formative assessment throughout.},
  author     = {Alexander, Rohan},
  date       = {2023-07-27},
  eprint     = {0QnHEAAAQBAJ},
  eprinttype = {googlebooks},
  isbn       = {978-1-00-089579-7},
  keywords   = {Business \& Economics / Statistics,Computers / Data Science / Data Analytics,Mathematics / Probability \& Statistics / General},
  langid     = {english},
  pagetotal  = {623},
  publisher  = {{CRC Press}},
  shorttitle = {Telling {{Stories}} with {{Data}}},
  title      = {Telling {{Stories}} with {{Data}}: {{With Applications}} in {{R}}}
}

@inproceedings{amato_tool_2010,
  abstract  = {We present a tool which performs abstract interpretation based static analysis of numerical variables. The novelty is that the analysis is parametric, and parameters are chosen by applying a variant of principal component analysis to partial execution traces of programs.},
  author    = {Amato, Gianluca and Parton, Maurizio and Scozzari, Francesca},
  booktitle = {Runtime Verification},
  date      = {2010},
  editor    = {Barringer, Howard and Falcone, Ylies and Finkbeiner, Bernd and Havelund, Klaus and Lee, Insup and Pace, Gordon and Roşu, Grigore and Sokolsky, Oleg and Tillmann, Nikolai},
  isbn      = {978-3-642-16612-9},
  location  = {Berlin, Heidelberg},
  pages     = {475--479},
  publisher = {Springer Berlin Heidelberg},
  title     = {A Tool Which Mines Partial Execution Traces to Improve Static Analysis}
}

@inproceedings{Amato2012RandomRA,
  author    = {Gianluca Amato and Francesca Scozzari},
  booktitle = {Logic Programming and Automated Reasoning},
  title     = {Random: R-Based Analyzer for Numerical Domains},
  url       = {https://api.semanticscholar.org/CorpusID:17945780},
  year      = {2012}
}

@misc{archiveOracleAnnounces,
  author = {},
  note   = {[Accessed 22-May-2023]},
  title  = {{O}racle {A}nnounces {A}vailability of {O}racle {A}dvanced {A}nalytics for {B}ig {D}ata},
  url    = {https://web.archive.org/web/20120211034626/https://www.oracle.com/us/corporate/press/1515738},
  year   = {2012}
}

@inproceedings{bahaidarah_reusable_2022,
  abstract   = {An essential part of research and scientific communication is researchers' ability to reproduce the results of others. While there have been increasing standards for authors to make data and code available, many of these files are hard to re-execute in practice, leading to a lack of research reproducibility. This poses a major problem for students and researchers in the same field who cannot leverage the previously published findings for study or further inquiry. To address this, we propose an open-source platform named RE3 that helps improve the reproducibility and readability of research projects involving R code. Our platform incorporates assessing code readability with a machine learning model trained on a code readability survey and an automatic containerization service that executes code files and warns users of reproducibility errors. This process helps ensure the reproducibility and readability of projects and therefore fast-track their verification and reuse.},
  author     = {Bahaidarah, Layan and Hung, Ethan and De Melo Oliveira, Andreas Francisco and Penumaka, Jyotsna and Rosario, Lukas and Trisovic, Ana},
  booktitle  = {2022 {{IEEE}} 18th {{International Conference}} on E-{{Science}} (e-{{Science}})},
  date       = {2022-10},
  doi        = {10.1109/eScience55777.2022.00079},
  eventtitle = {2022 {{IEEE}} 18th {{International Conference}} on E-{{Science}} (e-{{Science}})},
  pages      = {437--439},
  title      = {Toward {{Reusable Science}} with {{Readable Code}} and {{Reproducibility}}},
  url        = {https://ieeexplore.ieee.org/abstract/document/9973447},
  urldate    = {2024-01-05}
}

@article{baker20161,
  author    = {Baker, Monya},
  journal   = {Nature},
  number    = {7604},
  publisher = {{Nature}},
  title     = {1,500 scientists lift the lid on reproducibility},
  volume    = {533},
  year      = {2016}
}

@article{barker2022introducing,
  author    = {Barker, Michelle and Chue Hong, Neil P and Katz, Daniel S and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and others},
  journal   = {Scientific Data},
  number    = {1},
  pages     = {622},
  publisher = {Nature Publishing Group UK London},
  title     = {Introducing the FAIR Principles for research software},
  volume    = {9},
  year      = {2022}
}

@inproceedings{bertram2013renjin,
  author    = {Bertram, Alexander},
  booktitle = {The r user conference, useR! 2013 july 10-12 2013 university of castilla-la mancha, albacete, spain},
  number    = {30},
  pages     = {105},
  title     = {Renjin: A new r interpreter built on the jvm},
  volume    = {10},
  year      = {2013}
}

@article{chan_rang_2023,
  abstract     = {A complete declarative description of the computational environment is usually missing when researchers share their materials. Without such description, software obsolescence and missing system components can jeopardize computational reproducibility in the future, even when data and computer code are available. The R package rang is a complete solution for generating the declarative description for other researchers to automatically reconstruct the computational environment at a specific time point. The reconstruction process, based on Docker, has been tested for R code as old as 2001. The declarative description generated by rang satisfies the definition of a reproducible research compendium and can be shared as such. In this contribution, we show how rang can be used to make otherwise unexecutable code, spanning fields such as computational social science and bioinformatics, executable again. We also provide instructions on how to use rang to construct reproducible and shareable research compendia of current research. The package is currently available from CRAN (https://cran.r-project.org/web/packages/rang/index.html) and GitHub (https://github.com/chainsawriot/rang).},
  author       = {Chan, Chung-hong and Schoch, David},
  date         = {2023},
  doi          = {10.1371/journal.pone.0286761},
  issn         = {1932-6203},
  journaltitle = {PLOS ONE},
  keywords     = {Archaeology,Bioinformatics,Computer software,Metaanalysis,Operating systems,Programming languages,Reproducibility,Software tools},
  langid       = {english},
  number       = {6},
  pages        = {e0286761},
  publisher    = {{Public Library of Science}},
  shorttitle   = {Rang},
  title        = {Rang: {{Reconstructing}} Reproducible {{R}} Computational Environments},
  url          = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0286761},
  urldate      = {2024-01-05},
  volume       = {18}
}

@manual{checkglobals_chau_23,
  author = {Joris Chau},
  note   = {R package version 0.1.0},
  title  = {checkglobals: Static Analysis of R-Code Dependencies},
  url    = {https://CRAN.R-project.org/package=checkglobals},
  year   = {2023}
}

@manual{chk_thorley_23,
  author = {Joe Thorley and Kirill Müller and Ayla Pearson},
  note   = {R package version 0.9.1},
  title  = {chk: Check User-Supplied Function Arguments},
  url    = {https://CRAN.R-project.org/package=chk},
  year   = {2023}
}

@manual{cleanr_cullmann_23,
  author = {Andreas Dominik Cullmann},
  note   = {R package version 1.4.0},
  title  = {cleanr: Helps You to Code Cleaner},
  url    = {https://CRAN.R-project.org/package=cleanr},
  year   = {2023}
}

@manual{codetools_tierney_23,
  author = {Luke Tierney},
  note   = {R package version 0.2-19},
  title  = {codetools: Code Analysis Tools for R},
  url    = {https://CRAN.R-project.org/package=codetools},
  year   = {2023}
}

@manual{covr_hester_23,
  author = {Jim Hester},
  note   = {R package version 3.6.4},
  title  = {covr: Test Coverage for Packages},
  url    = {https://CRAN.R-project.org/package=covr},
  year   = {2023}
}

@manual{covtracer_kelkhoff_24,
  author = {Doug Kelkhoff and Andrew McNeil},
  note   = {R package version 0.0.0.9015},
  title  = {covtracer: Tools for contextualizing tests},
  url    = {https://github.com/genentech/covtracer},
  year   = {2024}
}

@article{cruwell_what_2023,
  abstract     = {In April 2019, Psychological Science published its first issue in which all Research Articles received the Open Data badge. We used that issue to investigate the effectiveness of this badge, focusing on the adherence to its aim at Psychological Science: sharing both data and code to ensure reproducibility of results. Twelve researchers of varying experience levels attempted to reproduce the results of the empirical articles in the target issue (at least three researchers per article). We found that all 14 articles provided at least some data and six provided analysis code, but only one article was rated to be exactly reproducible, and three were rated as essentially reproducible with minor deviations. We suggest that researchers should be encouraged to adhere to the higher standard in force at Psychological Science. Moreover, a check of reproducibility during peer review may be preferable to the disclosure method of awarding badges.},
  author       = {Crüwell, Sophia and Apthorp, Deborah and Baker, Bradley J. and Colling, Lincoln and Elson, Malte and Geiger, Sandra J. and Lobentanzer, Sebastian and Monéger, Jean and Patterson, Alex and Schwarzkopf, D. Samuel and Zaneva, Mirela and Brown, Nicholas J. L.},
  date         = {2023-04-01},
  doi          = {10.1177/09567976221140828},
  issn         = {0956-7976},
  journaltitle = {Psychol Sci},
  langid       = {english},
  number       = {4},
  pages        = {512--522},
  publisher    = {{SAGE Publications Inc}},
  shorttitle   = {What’s in a {{Badge}}?},
  title        = {What’s in a {{Badge}}? {{A Computational Reproducibility Investigation}} of the {{Open Data Badge Policy}} in {{One Issue}} of {{Psychological Science}}},
  url          = {https://doi.org/10.1177/09567976221140828},
  urldate      = {2024-01-05},
  volume       = {34}
}

@manual{cyclocomp_csardi_23,
  author = {Gabor Csardi},
  note   = {R package version 1.1.1},
  title  = {cyclocomp: Cyclomatic Complexity of R Code},
  url    = {https://CRAN.R-project.org/package=cyclocomp},
  year   = {2023}
}

@manual{dfgraph_kary_23,
  author = {Dan Kary},
  note   = {R package version 3.1.0},
  title  = {dfgraph: Visualize R Code with Data Flow Graphs},
  url    = {https://github.com/dkary/dfgraph}
}

@article{diera2023gencodesearchnet,
  author    = {Diera, Andor and Dahou, Abdelhalim and Galke, Lukas and Karl, Fabian and Sihler, Florian and Scherp, Ansgar},
  doi       = {10.48550/arXiv.2311.09707},
  journal   = {arXiv preprint arXiv:2311.09707},
  publisher = {GenBench Workshop '23},
  title     = {GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding},
  year      = {2023}
}

@dataset{drudze_2021_4912025,
  author    = {Drudze, Inese and
               Kalvāne, Gunta and
               Gribuste, Zane and
               Kalvāns, Andis},
  doi       = {10.5281/zenodo.4912025},
  month     = jun,
  publisher = {Zenodo},
  title     = {{Apple phenology data set and R script, related to
               publication "Full flowering phenology of apple
               tree (Malus domestica) in Pūre orchard, Latvia
               from 1959 to 2019"}},
  version   = {1.0},
  year      = 2021
}

@manual{flow_fabri_23,
  author = {Antoine Fabri},
  note   = {R package version 0.2.0},
  title  = {flow: View and Browse Code Using Flow Diagrams},
  url    = {https://CRAN.R-project.org/package=flow},
  year   = {2023}
}

@inproceedings{fluckiger2020sampling,
  author    = {Fl{\"u}ckiger, Olivier and W{\"a}lchli, Andreas and Krynski, Sebasti{\'a}n and Vitek, Jan},
  booktitle = {Proceedings of the 16th ACM SIGPLAN International Symposium on Dynamic Languages},
  pages     = {99--111},
  title     = {Sampling optimized code for type feedback},
  year      = {2020}
}

@manual{formatR_xie_23,
  author = {Yihui Xie},
  note   = {R package version 1.14},
  title  = {formatR: Format R Code Automatically},
  url    = {https://CRAN.R-project.org/package=formatR},
  year   = {2023}
}


@article{freese_advances_2022,
  abstract     = {Worries about a “credibility crisis” besieging science have ignited interest in research transparency and reproducibility as ways of restoring trust in published research. For quantitative social science, advances in transparency and reproducibility can be seen as a set of developments whose trajectory predates the recent alarm. We discuss several of these developments, including preregistration, data-sharing, formal infrastructure in the form of resources and policies, open access to research, and specificity regarding research contributions. We also discuss the spillovers of this predominantly quantitative effort towards transparency for qualitative research. We conclude by emphasizing the importance of mutual accountability for effective science, the essential role of openness for this accountability, and the importance of scholarly inclusiveness in figuring out the best ways for openness to be accomplished in practice.},
  author       = {Freese, Jeremy and Rauf, Tamkinat and Voelkel, Jan Gerrit},
  date         = {2022-09-01},
  doi          = {10.1016/j.ssresearch.2022.102770},
  issn         = {0049-089X},
  journaltitle = {Social Science Research},
  keywords     = {Open science,Reproducibility,Transparency},
  note         = {\section{Annotations\\
                  (1/6/2024, 3:54:08 PM)}
                  
                  \par
                  “The Royal Society adopted the motto “nullius in verba”: take no one’s word for it.” (Freese et al., 2022, p. 1)
                  \par
                  “Publication bias refers to various ways that the outcomeof a studyaffects whether or how it entersthe scientific record.” (Freese et al., 2022, p. 2)
                  \par
                  “The Open Science Framework offers both pre-registration hosting and a useful template (https://osf.io/k5wns);” (Freese et al., 2022, p. 3)
                  \par
                  “However, this problem is not necessarily inevitable, since statistical software generally has options for running backward compatible files.” (Freese et al., 2022, p. 4)
                  \par
                  “The path towards publishing statistical software (such as R packages) has been formalized (Wickham and Bryan 2021).” (Freese et al., 2022, p. 7)},
  pages        = {102770},
  title        = {Advances in Transparency and Reproducibility in the Social Sciences},
  url          = {https://www.sciencedirect.com/science/article/pii/S0049089X2200076X},
  urldate      = {2024-01-05},
  volume       = {107}
}

@article{garijo_nine_2022,
  abstract     = {Scientific software registries and repositories improve software findability and research transparency, provide information for software citations, and foster preservation of computational methods in a wide range of disciplines. Registries and repositories play a critical role by supporting research reproducibility and replicability, but developing them takes effort and few guidelines are available to help prospective creators of these resources. To address this need, the FORCE11 Software Citation Implementation Working Group convened a Task Force to distill the experiences of the managers of existing resources in setting expectations for all stakeholders. In this article, we describe the resultant best practices which include defining the scope, policies, and rules that govern individual registries and repositories, along with the background, examples, and collaborative work that went into their development. We believe that establishing specific policies such as those presented here will help other scientific software registries and repositories better serve their users and their disciplines.},
  author       = {Garijo, Daniel and Ménager, Hervé and Hwang, Lorraine and Trisovic, Ana and Hucka, Michael and Morrell, Thomas and Allen, Alice},
  date         = {2022-08-08},
  doi          = {10.7717/peerj-cs.1023},
  issn         = {2376-5992},
  journaltitle = {PeerJ Comput. Sci.},
  langid       = {english},
  pages        = {e1023},
  publisher    = {{PeerJ Inc.}},
  title        = {Nine Best Practices for Research Software Registries and Repositories},
  url          = {https://peerj.com/articles/cs-1023},
  urldate      = {2024-01-05},
  volume       = {8}
}

@book{garvin2004rcc,
  author    = {Garvin, John},
  publisher = {Rice University},
  title     = {RCC: A compiler for the R language for statistical computing},
  year      = {2004}
}

@misc{git_mro_19,
  title = {{M}icrosoft {R} {O}pen {S}ource},
  url   = https://github.com/microsoft/microsoft-r-open,
  year  = {2019}
}

@manual{globals_bengtsson_22,
  author = {Henrik Bengtsson},
  note   = {R package version 0.16.2},
  title  = {globals: Identify Global Objects in R Expressions},
  url    = {https://CRAN.R-project.org/package=globals},
  year   = {2022}
}

@manual{goodpractice_marks_22,
  author = {Karina Marks and Daniel {de Bortoli} and Gabor Csardi and Hannah Frick and Owen Jones and Hannah Alexander},
  note   = {R package version 1.0.4},
  title  = {goodpractice: Advice on R Package Building},
  url    = {https://CRAN.R-project.org/package=goodpractice},
  year   = {2022}
}

@article{ioannidis2005most,
  author    = {Ioannidis, John PA},
  journal   = {PLoS medicine},
  number    = {8},
  pages     = {e124},
  publisher = {Public Library of Science},
  title     = {Why most published research findings are false},
  volume    = {2},
  year      = {2005}
}

@article{kalibera2014fast,
  author    = {Kalibera, Tomas and Maj, Petr and Morandat, Floreal and Vitek, Jan},
  journal   = {ACM SIGPLAN Notices},
  number    = {7},
  pages     = {89--102},
  publisher = {ACM New York, NY, USA},
  title     = {A fast abstract syntax tree interpreter for R},
  volume    = {49},
  year      = {2014}
}

@manual{lang_codeanalysis_2023,
  author   = {Lang, Duncan and Fitzgeral, Clark and Espe, Matt and Ulle, Nick and Vince Buffalo},
  date     = {2023},
  subtitle = {Tools for static analysis of {{R}} code},
  title    = {{{CodeAnalysis}}},
  type     = {manual},
  url      = {https://github.com/duncantl/CodeAnalysis}
}

@manual{lang_codedepends_2018,
  author   = {Lang, Duncan and Peng, Roger and Nolan, Deborah and Becker, Gabriel},
  date     = {2018},
  subtitle = {{{Analysis}} of {{R}} Code for Reproducible Research and Code Comprehension},
  title    = {{{CodeDepends}}},
  type     = {manual},
  url      = {https://CRAN.R-project.org/package=CodeDepends}
}

@manual{languageserver_lai_23,
  author = {Randy Lai},
  note   = {R package version 0.3.16},
  title  = {languageserver: Language Server Protocol},
  url    = {https://CRAN.R-project.org/package=languageserver},
  year   = {2023}
}

@manual{lintr_hester_23,
  author = {Jim Hester and Florent Angly and Russ Hyde and Michael Chirico and Kun Ren and Alexander Rosenstock and Indrajeet Patil},
  note   = {R package version 3.1.0},
  title  = {lintr: A 'Linter' for R Code},
  url    = {https://CRAN.R-project.org/package=lintr},
  year   = {2023}
}

@software{ma_2021_5268024,
  author    = {Ma, Liang and
               Mi, Chunrong and
               Qu, Jiapeng and
               Ge, Deyan and
               Yang, Qisen and
               Wilcove, David},
  doi       = {10.5281/zenodo.5268024},
  month     = aug,
  publisher = {Zenodo},
  title     = {{Predicting range shifts of pikas
               (Mammalia, Ochotonidae) in China under scenarios
               incorporating land-use change, climate change, and
               dispersal limitations}},
  url       = {https://doi.org/10.5281/zenodo.5268024},
  year      = 2021
}


@unpublished{miljkovic_fair_2022,
  abstract    = {The lack of scientific openness is identified as one of the key challenges of computational reproducibility. In addition to Open Data, Free and Open-source Software (FOSS) and Open Hardware (OH) can address this challenge by introducing open policies, standards, and recommendations. However, while both FOSS and OH are free to use, study, modify, and redistribute, there are significant differences in sharing and reusing these artifacts. FOSS is increasingly supported with software repositories, but support for OH is lacking, potentially due to the complexity of its digital format and licensing. This paper proposes leveraging FAIR principles to make OH findable, accessible, interoperable, and reusable. We define what FAIR means for OH, how it differs from FOSS, and present examples of unique demands. Also, we evaluate dissemination platforms currently used for OH and provide recommendations.},
  author      = {Miljković, Nadica and Trisovic, Ana and Peer, Limor},
  date        = {2022-02-03},
  doi         = {10.5281/zenodo.5524414},
  eprint      = {2109.06045},
  eprintclass = {cs},
  eprinttype  = {arxiv},
  keywords    = {Computer Science - Digital Libraries,Computer Science - Software Engineering},
  note        = {Comment: 12 pages, 3 figures, 2 tables},
  title       = {Towards {{FAIR Principles}} for {{Open Hardware}}},
  url         = {http://arxiv.org/abs/2109.06045},
  urldate     = {2024-01-05}
}

@article{nealspeed,
  author = {Neal, Radford M},
  title  = {Speed Improvements in pqR: Current Status and Future Plans},
  url    = {https://glizen.com/radfordneal/ftp/pqR-dsc.pdf},
  year   = {2014}
}

@manual{pare_van_kessel_23,
  author = {Maarten {van Kessel}},
  note   = {R package version 0.1.12},
  title  = {PaRe: A Way to Perform Code Review or QA on Other Packages},
  url    = {https://github.com/darwin-eu-dev/PaRe},
  year   = {2023}
}

@book{patterson2020algebra,
  author    = {Patterson, Evan},
  publisher = {Stanford University},
  title     = {The algebra and machine representation of statistical models},
  year      = {2020}
}

@article{peikert2021reproducible,
  author    = {Peikert, Aaron and Brandmaier, Andreas M},
  journal   = {Quantitative and Computational Methods in Behavioral Sciences},
  pages     = {1--27},
  publisher = {PsychOpen},
  title     = {A reproducible data analysis workflow with R Markdown, Git, Make, and Docker},
  year      = {2021}
}

@inproceedings{pimentel_largescale_2019,
  abstract   = {Jupyter Notebooks have been widely adopted by many different communities, both in science and industry. They support the creation of literate programming documents that combine code, text, and execution results with visualizations and all sorts of rich media. The self-documenting aspects and the ability to reproduce results have been touted as significant benefits of notebooks. At the same time, there has been growing criticism that the way notebooks are being used leads to unexpected behavior, encourage poor coding practices, and that their results can be hard to reproduce. To understand good and bad practices used in the development of real notebooks, we studied 1.4 million notebooks from GitHub. We present a detailed analysis of their characteristics that impact reproducibility. We also propose a set of best practices that can improve the rate of reproducibility and discuss open challenges that require further research and development.},
  author     = {Pimentel, João Felipe and Murta, Leonardo and Braganholo, Vanessa and Freire, Juliana},
  booktitle  = {2019 {{IEEE}}/{{ACM}} 16th {{International Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  date       = {2019-05},
  doi        = {10.1109/MSR.2019.00077},
  eventtitle = {2019 {{IEEE}}/{{ACM}} 16th {{International Conference}} on {{Mining Software Repositories}} ({{MSR}})},
  issn       = {2574-3864},
  pages      = {507--517},
  title      = {A {{Large-Scale Study About Quality}} and {{Reproducibility}} of {{Jupyter Notebooks}}},
  url        = {https://ieeexplore.ieee.org/document/8816763},
  urldate    = {2024-01-06}
}


@manual{pkgstats_padgham_21,
  author = {Mark Padgham},
  note   = {R package version 0.0.3},
  title  = {pkgstats},
  url    = {https://github.com/ropensci-review-tools/pkgstats},
  year   = {2021}
}

@article{pruim_fostering_2023,
  abstract     = {Many data science students and practitioners don’t see the value in making time to learn and adopt good coding practices as long as the code “works”. However, code standards are an important part of modern data science practice, and they play an essential role in the development of data acumen. Good coding practices lead to more reliable code and save more time than they cost, making them important even for beginners. We believe that principled coding is vital for quality data science practice. To effectively instill these practices within academic programs, instructors and programs need to begin establishing these practices early, to reinforce them often, and to hold themselves to a higher standard while guiding students. We describe key aspects of good coding practices for data science, illustrating with examples in R and in Python, though similar standards are applicable to other software environments. Practical coding guidelines are organized into a top ten list.},
  author       = {Pruim, Randall and Gîrjău, Maria-Cristiana and Horton, Nicholas J.},
  date         = {2023-07-27},
  doi          = {10.1162/99608f92.97c9f60f},
  journaltitle = {Harvard Data Science Review},
  langid       = {english},
  note         = {\section{Annotations\\
                  (1/6/2024, 3:58:25 PM)}
                  
                  \par
                  “Even when the code is correct, following good coding practices makes the code easier to read and understand, saving time and promoting good communication among team members.” (Pruim et al., 2023, p. 2)
                  \par
                  “It is really painful when taking a graduate level data science course and the instructor’s code is considerably below any acceptable standard in the real world. Here is some real life code from a demo offered for the current homework. . .” (Pruim et al., 2023, p. 4)
                  \par
                  “2.1. The Four C’s.” (Pruim et al., 2023, p. 5)
                  \par
                  “2.3.1. Choose good names” (Pruim et al., 2023, p. 6)
                  \par
                  “styler (Müller and Walthert 2022) and formatR (Xie 2022)” (Pruim et al., 2023, p. 8)
                  \par
                  “2.3.4. Select a coherent, minimal, yet powerful toolkit.” (Pruim et al., 2023, p. 9)
                  \par
                  “A fortunate recent development is the converging of ideas in R and Python.” (Pruim et al., 2023, p. 9)
                  \par
                  “2.3.6. Take advantage of a functional programming style.” (Pruim et al., 2023, p. 14)
                  \par
                  “Recently, functional techniques have experienced a surge in interest because they can produce efficient and elegant solutions to many modern problems. A functional style tends to create functions that can easily be analysed in isolation (i.e., using only local information), and hence is often much easier to automatically optimise or parallelise.” (Pruim et al., 2023, p. 15)
                  \par
                  “For loops, for example, should mostly be avoided in R and replaced with equivalent (but more efficient) functional programming structures.” (Pruim et al., 2023, p. 15)
                  \par
                  “1. Choose good names. 2. Follow a style guide consistently. 3. Create documents using tools that support reproducible workflows. 4. Select a coherent, minimal, yet powerful toolkit. 5. Don’t Repeat Yourself (DRY). 6. Take advantage of a functional programming style. 7. Employ consistency checks. 8. Learn how to debug and to ask for help. 9. Get (version) control of the situation. 10. Be multilingual.” (Pruim et al., 2023, p. 20)
                  \par
                  “Hold yourself (as instructor) to a higher standard while gently guiding students to better coding practices.” (Pruim et al., 2023, p. 21)
                  \par
                  “Use live coding demonstrations to model appropriate practice.” (Pruim et al., 2023, p. 22)
                  \par
                  “Regularly comment on student code practices” (Pruim et al., 2023, p. 22)
                  \par
                  “ell. 5.” (Pruim et al., 2023, p. 22)
                  \par
                  “Provide opportunities for students to collaborate on code and to refactor their own code.” (Pruim et al., 2023, p. 22)
                  \par
                  For C’s:
                  \par
                  Correctness, Clarity, Containment, Consistency
                  \par
                  Present good coding standrads in teaching},
  number       = {3},
  title        = {Fostering {{Better Coding Practices}} for {{Data Scientists}}},
  url          = {https://hdsr.mitpress.mit.edu/pub/8wsiqh1c},
  urldate      = {2024-01-05},
  volume       = {5}
}

@misc{pypl2024,
  author = {},
  title  = {{PYPL} --- {P}opularit{Y} of {P}rogramming {L}anguage index},
  url    = {https://web.archive.org/web/20240106152629/https://pypl.github.io/PYPL.html},
  year   = {2024}
}

@manual{r_team_23,
  address      = {Vienna, Austria},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  title        = {R: A Language and Environment for Statistical Computing},
  url          = {https://www.R-project.org/},
  year         = {2023}
}

@online{rahman_how_2023,
  abstract    = {ChatGPT, a recently developed product by openAI, is successfully leaving its mark as a multi-purpose natural language based chatbot. In this paper, we are more interested in analyzing its potential in the field of computational biology. A major share of work done by computational biologists these days involve coding up bioinformatics algorithms, analyzing data, creating pipelining scripts and even machine learning modeling and feature extraction. This paper focuses on the potential influence (both positive and negative) of ChatGPT in the mentioned aspects with illustrative examples from different perspectives. Compared to other fields of computer science, computational biology has - (1) less coding resources, (2) more sensitivity and bias issues (deals with medical data) and (3) more necessity of coding assistance (people from diverse background come to this field). Keeping such issues in mind, we cover use cases such as code writing, reviewing, debugging, converting, refactoring and pipelining using ChatGPT from the perspective of computational biologists in this paper.},
  author      = {Rahman, Chowdhury Rafeed and Wong, Limsoon},
  date        = {2023-12-04},
  doi         = {10.48550/arXiv.2309.09126},
  eprint      = {2309.09126},
  eprintclass = {cs},
  eprinttype  = {arxiv},
  keywords    = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  note        = {\section{Annotations\\
                 (1/6/2024, 3:59:38 PM)}
                 
                 \par
                 “ChatGPT can go a long way in helping computational biologists with programming. We need to be open to such new technologies while being cautious of their shortcomings.” (Rahman and Wong, 2023, p. 11)},
  pubstate    = {preprint},
  title       = {How Much Can {{ChatGPT}} Really Help {{Computational Biologists}} in {{Programming}}?},
  url         = {http://arxiv.org/abs/2309.09126},
  urldate     = {2024-01-05}
}

@manual{rclean_lau_22,
  author = {Matthew Lau},
  note   = {R package version 1.1.8},
  title  = {Rclean: A Tool for Writing Cleaner, More Transparent Code},
  url    = {https://github.com/MKLau/Rclean},
  year   = {2022}
}

@manual{rco_rodriguez_21,
  author = {Juan Cruz Rodriguez},
  note   = {R package version 1.0.2},
  title  = {rco: The R Code Optimizer},
  url    = {https://CRAN.R-project.org/package=rco},
  year   = {2021}
}

@misc{RLang,
  author = {{R Core Team}},
  note   = {Accessed: 2023-05-04},
  title  = {{R Language Definition}},
  url    = {https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf},
  year   = 2023
}

@dataset{robertson_2020_4081494,
  author    = {Robertson, Joshua},
  doi       = {10.5061/dryad.rfj6q5774},
  month     = oct,
  publisher = {Zenodo},
  title     = {{Social hierarchy reveals thermoregulatory trade-
               offs in response to repeated stressors}},
  url       = {https://doi.org/10.5061/dryad.rfj6q5774},
  year      = 2020
}

@manual{roger_goulet_23,
  author = {Vincent Goulet and Samuel Fréchette and Jean-Christophe Langlois},
  note   = {R package version 1.5-1},
  title  = {roger: Automated Grading of R Scripts},
  url    = {https://CRAN.R-project.org/package=roger},
  year   = {2023}
}

@misc{rProjectComprehensiveArchive,
  author       = {},
  howpublished = {\url{https://cran.r-project.org/}},
  title        = {{T}he {C}omprehensive {R} {A}rchive {N}etwork --- cran.r-project.org},
  year         = {2024}
}

@misc{rProjectJournal,
  author = {},
  note   = {[Accessed 22-May-2023]},
  title  = {The {R} {J}ournal},
  url    = {https://journal.r-project.org/}
}

@manual{rstatic_ulle_19,
  author = {Nick Ulle and Duncan {Temple Lang}},
  note   = {R package version 0.1.0-0006},
  title  = {rstatic: Low-level Static Analysis Tools for R Code},
  year   = {2019}
}

@manual{RStudio,
  address      = {Boston, MA},
  author       = {{RStudio Team}},
  organization = {RStudio, PBC},
  title        = {RStudio: Integrated Development Environment for R},
  url          = {http://www.rstudio.com/},
  year         = {2022}
}

@manual{rstudio_posit_23,
  address      = {Boston, MA},
  author       = {{Posit team}},
  organization = {Posit Software, PBC},
  title        = {RStudio: Integrated Development Environment for R},
  url          = {http://www.posit.co/},
  year         = {2023}
}

@manual{rtypeinference_ulle_21,
  author = {Nick Ulle and Duncan {Temple Lang}},
  note   = {R package version 0.5.0-0030},
  title  = {RTypeInference: Infer Types of Inputs and Outputs for R Expressions},
  year   = {2021}
}

@misc{sen2017rosa,
  archiveprefix = {arXiv},
  author        = {Rathijit Sen and Jianqiao Zhu and Jignesh M. Patel and Somesh Jha},
  eprint        = {1704.02996},
  primaryclass  = {cs.PL},
  title         = {ROSA: R Optimizations with Static Analysis},
  year          = {2017}
}

@article{sharma_analytical_2023,
  abstract     = {Data-driven computational analysis is becoming increasingly important in biomedical research, as the amount of data being generated continues to grow. However, the lack of practices of sharing research outputs, such as data, source code and methods, affects transparency and reproducibility of studies, which are critical to the advancement of science. Many published studies are not reproducible due to insufficient documentation, code, and data being shared. We conducted a comprehensive analysis of 453 manuscripts published between 2016–2021 and found that 50.1\% of them fail to share the analytical code. Even among those that did disclose their code, a vast majority failed to offer additional research outputs, such as data. Furthermore, only one in ten papers organized their code in a structured and reproducible manner. We discovered a significant association between the presence of code availability statements and increased code availability (p=2.71×10−9). Additionally, a greater proportion of studies conducting secondary analyses were inclined to share their code compared to those conducting primary analyses (p=1.15*10−07). In light of our findings, we propose raising awareness of code sharing practices and taking immediate steps to enhance code availability to improve reproducibility in biomedical research. By increasing transparency and reproducibility, we can promote scientific rigor, encourage collaboration, and accelerate scientific discoveries. We must prioritize open science practices, including sharing code, data, and other research products, to ensure that biomedical research can be replicated and built upon by others in the scientific community.},
  author       = {Sharma, Nitesh Kumar and Ayyala, Ram and Deshpande, Dhrithi and Patel, Yesha M and Munteanu, Viorel and Ciorba, Dumitru and Fiscutean, Andrada and Vahed, Mohammad and Sarkar, Aditya and Guo, Ruiwei and Moore, Andrew and Darci-Maher, Nicholas and Nogoy, Nicole A and Abedalthagafi, Malak S. and Mangul, Serghei},
  date         = {2023-08-07},
  doi          = {10.1101/2023.07.31.551384},
  eprint       = {37609176},
  eprinttype   = {pmid},
  journaltitle = {bioRxiv},
  note         = {Shares are mostly in non-Notebook formats!},
  pages        = {2023.07.31.551384},
  pmcid        = {PMC10441317},
  title        = {Analytical Code Sharing Practices in Biomedical Research},
  url          = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10441317/},
  urldate      = {2024-01-05}
}

@article{sihler2023constructing,
  author    = {Sihler, Florian},
  publisher = {Ulm University},
  title     = {Constructing a static program slicer for R programs},
  year      = {2023}
}

@inproceedings{sihler2024anatomy,
  author    = {Sihler, Florian and Pietzschmann, Lukas and Straub, Raphael and Tichy, Matthias and Diera, Andor and Dahou, Abdelhalim},
  booktitle = {Mining Software Repositories},
  publisher = {MSR},
  title     = {On the Anatomy of Real-World R Code for Static Analysis},
  year      = {2024}
}

@manual{similar_bartoszuk_23,
  author = {Maciej Bartoszuk and Marek Gagolewski},
  note   = {R package version 1.0.8},
  title  = {SimilaR: R Source Code Similarity Evaluation},
  url    = {https://CRAN.R-project.org/package=SimilaR},
  year   = {2020}
}

@manual{styler_muller_23,
  author = {Kirill Müller and Lorenz Walthert},
  note   = {R package version 1.10.2},
  title  = {styler: Non-Invasive Pretty Printing of R Code},
  url    = {https://CRAN.R-project.org/package=styler},
  year   = {2023}
}

@inproceedings{talbot_riposte_2012,
  abstract   = {There is a growing utilization gap between modern hardware and modern programming languages for data analysis. Due to power and other constraints, recent processor design has sought improved performance through increased SIMD and multi-core parallelism. At the same time, high-level, dynamically typed languages for data analysis have become popular. These languages emphasize ease of use and high productivity, but have, in general, low performance and limited support for exploiting hardware parallelism.},
  author     = {Talbot, Justin and DeVito, Zachary and Hanrahan, Pat},
  booktitle  = {Proceedings of the 21st International Conference on {{Parallel}} Architectures and Compilation Techniques},
  date       = {2012-09-19},
  doi        = {10.1145/2370816.2370825},
  eventtitle = {{{PACT}} '12: {{International Conference}} on {{Parallel Architectures}} and {{Compilation Techniques}}},
  isbn       = {978-1-4503-1182-3},
  langid     = {english},
  location   = {{Minneapolis Minnesota USA}},
  pages      = {43--52},
  publisher  = {{ACM}},
  shorttitle = {Riposte},
  title      = {Riposte: A Trace-Driven Compiler and Parallel {{VM}} for Vector Code in {{R}}},
  url        = {https://dl.acm.org/doi/10.1145/2370816.2370825},
  urldate    = {2024-01-09}
}

@article{thimbleby_improving_2023,
  author       = {Thimbleby, Harold},
  date         = {2023},
  issn         = {0010-4620},
  journaltitle = {The Computer Journal},
  note         = {\section{Annotations\\
                  (1/6/2024, 4:06:32 PM)}
                  
                  \par
                  “Professional Software Engineers can help, particularly in critical fields such as public health, climate change and energy” (Thimbleby, 2023, p. 1)
                  \par
                  “In the survey sample, 81\% of papers were published in leading journals that have code policies (which themselves are weak), but 42\% of surveyed papers published in those journals breached their own policies.” (Thimbleby, 2023, p. 1)
                  \par
                  “A study of 863 878 Python-coded Jupyter notebooks [18] found a 76\% failure rate for code to complete execution successfully. Trisovic et al. [19] performed a study of 9 000 research codes written in the language R on Dataverse, an opensource repository maintained by Harvard University’s Institute for Quantitative Social Sciences. They found a comparable result that 74\% of the code files analyzed failed.” (Thimbleby, 2023, p. 2)
                  \par
                  “2.2. Computable papers” (Thimbleby, 2023, p. 4)
                  \par
                  “However, there is no structure to using general-purpose systems like HTML, LATEX or Rmarkdown, which means authors may make unnoticed mistakes” (Thimbleby, 2023, p. 4)
                  \par
                  “A taut review of such systems is Perkel [30], whereas [31] discusses in-depth the design trade-offs of one powerful approach, Maneage; the paper [31] includes a substantial and useful literature review (in its appendix).” (Thimbleby, 2023, p. 4)
                  \par
                  “The siren call of over-fitting code” (Thimbleby, 2023, p. 8)
                  \par
                  “A co-author disclosed [74] that the code was thousands of lines long and was undocumented code.” (Thimbleby, 2023, p. 12)
                  \par
                  “The code in [9, 73] has been ‘reproduced,’ as reported in Nature [83, 84], but this so-called reproduction merely confirms that the code can be run again and produce comparable results.” (Thimbleby, 2023, p. 13)
                  \par
                  “1) Is the code valid: does it do what the paper claims?10 2) Do other scientists, including reviewers and the authors, understand the code? 3) Does the code implement the methods described in the paper? 4) Has the code been over-fitted or tweaked to support specific claims in the paper? 5) Is there a definitive version of code? 6) Is the code controlled and signed? 7) What limitations does the code have? 8) Was the code developed to any standard, and does it comply to that standard? 9) How does the code protect against data, coding, and human error? 10) Was the code tested adequately? 11) Does the code depend on arbitrary parameters, data, or code to over-fit to obtain the published results? 12) Is the code documented adequately, so we know what it is trying to do, and how? 13) ... and so forth” (Thimbleby, 2023, p. 13)
                  \par
                  “nalogously, and supplementing Ethics Boards, it is argued here that Software Engineering Boards (SEBs) would authorize as well as provide advice to guide the implementation of quality Software Engineering to support research and publication processes. Just as journals require conf licts of interest statements, data availability statements and ethics board clearance, we should move to scientific papers and funded research being required to include formal Software Engineering Board statements.” (Thimbleby, 2023, p. 15)
                  \par
                  “Action must be interdisciplinary” (Thimbleby, 2023, p. 17)
                  \par
                  We need interdisciplinary work/collaboration (SE boards…)},
  publisher    = {{Oxford University Press}},
  title        = {Improving {{Science That Uses Code}}}
}


@manual{tracer_tu_dortmund_15,
  author = {TU Dortmund University},
  title  = {TraceR: A Profiling Tool for R. TU Dortmund University},
  url    = {https://github.com/allr/traceR-installer},
  year   = {2015}
}

@article{trisovic_largescale_2022,
  abstract     = {This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74\% of R files failed to complete without error in the initial execution, while 56\% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.},
  author       = {Trisovic, Ana and Lau, Matthew K. and Pasquier, Thomas and Crosas, Mercè},
  date         = {2022},
  doi          = {10.1038/s41597-022-01143-6},
  issn         = {2052-4463},
  issue        = {1},
  journaltitle = {Sci Data},
  keywords     = {Information technology,Research data,Software},
  langid       = {english},
  note         = {\section{Annotations\\
                  (1/6/2024, 3:54:11 PM)}
                  
                  \par
                  “ten questions” (Trisovic et al., 2022, p. 1)
                  \par
                  “2000 replication datasets” (Trisovic et al., 2022, p. 1)
                  \par
                  “9000 unique R files published from 2010 to 2020” (Trisovic et al., 2022, p. 1)
                  \par
                  “74\% of R files failed” (Trisovic et al., 2022, p. 1)
                  \par
                  “56\% failed when code cleaning was applied” (Trisovic et al., 2022, p. 1)
                  \par
                  “we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories” (Trisovic et al., 2022, p. 1)
                  \par
                  “Most popular code file types on Harvard Dataverse (Oct, 2020). Of the top two, R is open source and free” (Trisovic et al., 2022, p. 2)
                  \par
                  “The image contains three independent R environments, each with a different version of the~R interpreter and corresponding r-essentials, a bundle of approximately 200 most popular R packages for data science” (Trisovic et al., 2022, p. 3)
                  \par
                  “Though a total of 2,170 replication packages contained R code and were visible through the Dataverse API, we successfully retrieved 2109 (97\%) of them.” (Trisovic et al., 2022, p. 3)
                  \par
                  “In particular, it removes absolute file paths, standardizes file encoding, and identifies and imports used libraries to set up a proper execution environment” (Trisovic et al., 2022, p. 3)
                  \par
                  “We observe that only a small fraction of datasets contain R Markdown (3.11\%) and Rnw files (0.24\%), meaning that to date few researchers have employed these methods” (Trisovic et al., 2022, p. 4)
                  \par
                  “we can approximate that behind each published dataset lies about 320 R code lines.” (Trisovic et al., 2022, p. 4)
                  \par
                  “According to IBM studies, intuitive variable naming contributes more to code readability than comments, or for that matter, any other factor” (Trisovic et al., 2022, p. 5) Just reference a \textasciitilde 900 page book
                  
                  Maybe
                  
                  Fagan, Michael E. "Design and Code Inspections to Reduce Errors in Program Development." IBM Systems Journal 15, no. 3 (1976): 182–211.
                  \par
                  “Out of 3070 R files, we find that 621 use variables that are one or two characters long. However, the average length of variable names is 10, which is a positive finding as such a name could contain one, two, or more English words and be sufficiently descriptive to a reuser” (Trisovic et al., 2022, p. 5)
                  \par
                  “We find 9 out of 2091 replication packages that have a DESCRIPTION file and 30 where the word description is contained in any of the file names” (Trisovic et al., 2022, p. 6)
                  \par
                  “We have not found a single install.R among the analyzed datasets, but we found similar files such as: installrequirements.R, 000install.R, packageinstallation.R or postinstall” (Trisovic et al., 2022, p. 6)
                  \par
                  “Most code files had other, more complex errors after code cleaning resolved the initial ones” (Trisovic et al., 2022, p. 8)
                  \par
                  “f we exclude all datasets that contain code in other programming languages, the file-level success rate is 38\% (out of 2483 files), and the dataset-level success rate is 45\% (out of 928 datasets)” (Trisovic et al., 2022, p. 8)
                  \par
                  “We find that R 3.2, released in 2015, performed best with the replication packages released in 2016 and 2017 (Fig.~11a).” (Trisovic et al., 2022, p. 9)
                  \par
                  “ecause R 4.0 was released in summer 2020, likely none of the examined replication packages originally used that version of the software. It is important to note that the subversion R 3.6 was the last before the R 4.0 (i.e., there was no R 3.7 or later subversions).” (Trisovic et al., 2022, p. 9)
                  \par
                  “A potential cause may be the use of incompatible library versions in our re-execution step as the R software automatically installs the latest version of a library.” (Trisovic et al., 2022, p. 9)
                  \par
                  “The Harvard Dataverse repository was initially geared toward social science” (Trisovic et al., 2022, p. 10)
                  \par
                  “While successful code re-execution is not a sufficient measure for reproducibility, our sample suggests that it might be a good indicator that computational reproducibility will be successful.” (Trisovic et al., 2022, p. 11)
                  \par
                  “Extensive guides on code practices have been published30–34 and are available online35.” (Trisovic et al., 2022, p. 12)
                  \par
                  “Our code cleaning approach is relatively simple to minimize the chance of “breaking the code”, and we do not use static analysis packages such as goodpractice or lintr as they do not make changes in the code automatically.” (Trisovic et al., 2022, p. 13)
                  \par
                  “Python 2.7” (Trisovic et al., 2022, p. 14)},
  number       = {1},
  pages        = {60},
  publisher    = {{Nature Publishing Group}},
  title        = {A Large-Scale Study on Research Code Quality and Execution},
  url          = {https://www.nature.com/articles/s41597-022-01143-6},
  urldate      = {2024-01-05},
  volume       = {9}
}

@inproceedings{wang2014optimizing,
  author    = {Wang, Haichuan and Wu, Peng and Padua, David},
  booktitle = {Proceedings of Annual IEEE/ACM International Symposium on Code Generation and Optimization},
  pages     = {295--305},
  title     = {Optimizing r vm: Allocation removal and path length reduction via interpreter-level specialization},
  year      = {2014}
}

@article{weiser_program_1984,
  abstract     = {Program slicing is a method for automatically decomposing programs by analyzing their data flow and control flow. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a “slice,” is an independent program guaranteed to represent faithfully the original program within the domain of the specified subset of behavior. Some properties of slices are presented. In particular, finding statement-minimal slices is in general unsolvable, but using data flow analysis is sufficient to find approximate slices. Potential applications include automatic slicing tools for debuggng and parallel processing of slices.},
  author       = {Weiser, Mark},
  date         = {1984-07},
  doi          = {10.1109/TSE.1984.5010248},
  eventtitle   = {{{IEEE Transactions}} on {{Software Engineering}}},
  issn         = {1939-3520},
  journaltitle = {IEEE Transactions on Software Engineering},
  keywords     = {Algorithms,Data flow analysis,Data mining,debugging,Debugging,human factors,Merging,parallel processing,Probability density function,program maintenance,program metrics,Program processors,slicing,software tools,Trajectory},
  number       = {4},
  pages        = {352--357},
  publisher    = {IEEE Transactions on Software Engineering},
  title        = {Program {{Slicing}}},
  volume       = {SE-10}
}


@book{weiser1979program,
  author    = {Weiser, Mark David},
  date      = {1979},
  publisher = {{University of Michigan}},
  title     = {Program Slices: Formal, Psychological, and Practical Investigations of an Automatic Program Abstraction Method}
}

@article{wonsil_reproducibility_2023,
  abstract     = {Recent studies demonstrated that the reproducibility of previously published computational experiments is inadequate. Many of these published computational experiments never recorded or preserved their computational environment, including packages installed in the language, libraries installed on the host system, and file locations. Researchers have created reproducibility tools to help mitigate this problem, but these tools assume the experiment currently executes. Thus, these tools do not facilitate reproducibility of the large number of published experiments. This situation is not improving; researchers continue to publish without using reproducibility tools. We define a framework to distinguish between actions taken by a researcher to facilitate reproducibility in the presence of a computational environment and actions taken by a researcher to enable reproduction of an experiment when that environment has been lost to clarify the gap between what existing reproducibility tools are capable of and what is required to reproduce published experiments. The difference between these approaches lies in the availability of a computational environment. Researchers that provide access to the original computational environment perform proactive reproducibility, while those who do not enable only retroactive reproducibility. We present Reproducibility as a Service (RaaS), which is, to the best of our knowledge, the first reproducibility tool explicitly designed to facilitate retroactive reproducibility. We demonstrate how RaaS fixes many common errors found in R scripts on Harvard's Dataverse and preserves a recreated computational environment. Finally, we discuss how a retroactive reproducibility service such as RaaS is also helpful as an ‘artifact evaluation assistant’ in a journal's publication pipeline.},
  author       = {Wonsil, Joseph and Boufford, Nichole and Agrawal, Prakhar and Chen, Christopher and Cui, Tianhang and Sivaram, Akash and Seltzer, Margo},
  date         = {2023},
  doi          = {10.1002/spe.3202},
  issn         = {1097-024X},
  journaltitle = {Software: Practice and Experience},
  keywords     = {containers,provenance,R,reproducibility,static analysis},
  langid       = {english},
  number       = {7},
  pages        = {1543--1571},
  publisher    = {Software: Practice and Experience},
  title        = {Reproducibility as a Service},
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3202},
  urldate      = {2024-01-05},
  volume       = {53}
}
